{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q__J6WJ6mmK"
      },
      "source": [
        "### Read training, dev and unlabeled test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01UpUDfY6mmR"
      },
      "source": [
        "The following provides a starting code (Python 3) of how to read the labeled training and dev sentence pairs, and unlabeled test sentence pairs, into lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zrraa1yh6mmS"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0kqXGltR6mmU"
      },
      "outputs": [],
      "source": [
        "train, dev, test = [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLzxfMs56mmV"
      },
      "outputs": [],
      "source": [
        "with open('./data/pnli_train.csv', encoding='utf-8') as fp:\n",
        "    csvreader = csv.reader(fp)\n",
        "    for x in csvreader:\n",
        "        # x[2] will be the label (0 or 1). x[0] and x[1] will be the sentence pairs.\n",
        "        train.append(x)\n",
        "print (len(train))\n",
        "print (train[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbo4GmiI6mmX"
      },
      "outputs": [],
      "source": [
        "with open('./data/pnli_dev.csv', encoding='utf-8') as fp:\n",
        "    csvreader = csv.reader(fp)\n",
        "    for x in csvreader:\n",
        "        # x[2] will be the label (0 or 1). x[0] and x[1] will be the sentence pairs.\n",
        "        dev.append(x)\n",
        "print (len(dev))\n",
        "print (dev[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taTBJw8r6mmY"
      },
      "outputs": [],
      "source": [
        "with open('./data/pnli_test_unlabeled.csv', encoding='utf-8') as fp:\n",
        "    csvreader = csv.reader(fp)\n",
        "    for x in csvreader:\n",
        "        # x[0] and x[1] will be the sentence pairs.\n",
        "        test.append(x)\n",
        "print (len(test))\n",
        "print (test[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTcMRUKN6mmZ"
      },
      "source": [
        "### Main Code Body"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR-vgCuB6mma"
      },
      "source": [
        "You may choose to experiment with different methods using your program. However, you need to embed the training and inference processes at here. We will use your prediction on the unlabeled test data to grade, while checking this part to understand how your method has produced the predictions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "fMw2cZ_-Qs5y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import gc\n",
        "from transformers import BertTokenizer\n",
        "from transformers import AdamW\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings"
      ],
      "metadata": {
        "id": "bI_HfsqB30IB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame(train, columns=['precondition', 'statement', 'label'])\n",
        "dev_df = pd.DataFrame(dev, columns=['precondition', 'statement', 'label'])\n",
        "test_df = pd.DataFrame(test, columns=['precondition', 'statement'])\n",
        "\n",
        "train_df['label'] = train_df['label'].astype(int)\n",
        "dev_df['label'] = dev_df['label'].astype(int)"
      ],
      "metadata": {
        "id": "9F-Fb1Tn30GZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "tQ-GWf4W30DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_df.head()"
      ],
      "metadata": {
        "id": "CFGPExOl30BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "QEZ3709E3zFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = 'roberta-base'\n",
        "\n",
        "learning_rate = 2e-5\n",
        "epsilon = 1e-8\n",
        "\n",
        "max_length = 128\n",
        "\n",
        "num_epochs = 4\n",
        "batch_size = 32\n"
      ],
      "metadata": {
        "id": "zPoAk4q-3y6_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "\n",
        "# roberta-base\n",
        "print('Load tokenizer', model_type)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_type)"
      ],
      "metadata": {
        "id": "Eh7iIuXW3yyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not (torch.cuda.is_available()):\n",
        "  device = \"cpu\"\n",
        "else:\n",
        "  device = \"cuda\"\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "cCJMJAHm4FMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CreateTrainValDataset(Dataset):\n",
        "  def __init__(self, statement, precondition, label, tokenizer, max_length):\n",
        "    self.statement = statement\n",
        "    self.precondition = precondition\n",
        "    self.label = label\n",
        "    self. tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.statement) \n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    statement_item = self.statement[index]\n",
        "    precondition_item = self.precondition[index]\n",
        "    label_item = self.label[index]\n",
        "\n",
        "    tokenized_input = tokenizer.encode_plus( statement_item, precondition_item,\n",
        "                                            add_special_tokens = True,\n",
        "                                            max_length = self.max_length,\n",
        "                                            padding = 'max_length',\n",
        "                                            truncation = True,\n",
        "                                            return_attention_mask = True,\n",
        "                                            return_tensors = 'pt')\n",
        "    return {\n",
        "            'input_ids': tokenized_input['input_ids'].flatten(),\n",
        "            'attention_mask': tokenized_input['attention_mask'].flatten(),\n",
        "            'targets': torch.tensor(label_item)\n",
        "        }\n",
        "                                          \n",
        "        "
      ],
      "metadata": {
        "id": "VkJCAjJR4FLF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CreateTrainValDataset(train_df['statement'], train_df['precondition'], \n",
        "                                   train_df['label'], tokenizer, max_length)\n",
        "\n",
        "dev_data = CreateTrainValDataset(dev_df['statement'], dev_df['precondition'], \n",
        "                                   dev_df['label'], tokenizer, max_length)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True,num_workers=2)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(dev_data,batch_size=batch_size,shuffle=True,num_workers=2)\n",
        "print(len(train_dataloader))\n",
        "print(len(val_dataloader))"
      ],
      "metadata": {
        "id": "CqKe5RNh4FHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking train dataset is working\n",
        "train_data.__getitem__(0)"
      ],
      "metadata": {
        "id": "Jm8UBmtu4FFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "from transformers import RobertaForSequenceClassification\n",
        "\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_type, num_labels = 2)\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr = learning_rate, eps = epsilon)"
      ],
      "metadata": {
        "id": "f_vW15Gb3yqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting seed value\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "YtDxQ1tx4Paj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0, num_epochs):\n",
        "    \n",
        "  print('\\nEpoch', (epoch + 1),\"/\",num_epochs)\n",
        "  \n",
        "  val_preds = []\n",
        "  ground_truth = []\n",
        "\n",
        "  ##Training\n",
        "  print('Training Metrics')\n",
        "  \n",
        "  model.train()\n",
        "  torch.set_grad_enabled(True)\n",
        "\n",
        "  total_train_loss = 0\n",
        "\n",
        "  for i, sample in enumerate(train_dataloader):\n",
        "      sample_input_ids = sample[\"input_ids\"].to(device)\n",
        "      sample_atten_mask = sample[\"attention_mask\"].to(device)\n",
        "      sample_labels =  sample[\"targets\"].to(device)\n",
        "\n",
        "      model.zero_grad()        \n",
        "      outputs = model(sample_input_ids, \n",
        "                  attention_mask=sample_atten_mask,\n",
        "                  labels=sample_labels)\n",
        "      \n",
        "      train_loss = outputs[0]\n",
        "      total_train_loss +=  train_loss.item()\n",
        "      optimizer.zero_grad()\n",
        "      train_loss.backward()        \n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step() \n",
        "  print('Train loss:' ,total_train_loss)\n",
        "\n",
        "  ## Validation\n",
        "  \n",
        "  print('\\nValidation Metrics')\n",
        "  model.eval()\n",
        "  total_val_loss = 0\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for j, sample in enumerate(val_dataloader):\n",
        "      sample_input_ids = sample[\"input_ids\"].to(device)\n",
        "      sample_atten_mask = sample[\"attention_mask\"].to(device)\n",
        "      sample_labels =  sample[\"targets\"].to(device)     \n",
        "\n",
        "\n",
        "\n",
        "      outputs = model(sample_input_ids, \n",
        "              attention_mask=sample_atten_mask, \n",
        "              labels=sample_labels)\n",
        "      \n",
        "      val_loss,preds = outputs[0],outputs[1]\n",
        "      total_val_loss += val_loss.item()\n",
        "      \n",
        "      val_preds_batch = preds.detach().cpu().numpy()\n",
        "      ground_truth_batch = sample_labels.to('cpu').numpy()\n",
        "\n",
        "      ground_truth.extend(ground_truth_batch)\n",
        "\n",
        "      if j != 0: \n",
        "          val_preds = np.vstack((val_preds, val_preds_batch))\n",
        "\n",
        "      else:\n",
        "          val_preds = val_preds_batch\n",
        "  \n",
        "    y_pred = np.argmax(val_preds, axis=1)\n",
        "    val_accuracy = accuracy_score(ground_truth, y_pred)\n",
        "    \n",
        "    print('Validation loss:' ,total_val_loss)\n",
        "    print('Validation accuracy: ', val_accuracy)\n",
        "    \n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "P6h3Es464PWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CreateTestDataset(Dataset):\n",
        "  def __init__(self, statement, precondition, tokenizer, max_length):\n",
        "    self.statement = statement\n",
        "    self.precondition = precondition\n",
        "    self. tokenizer = tokenizer\n",
        "    self.max_length = max_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.statement) \n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    statement_item = self.statement[index]\n",
        "    precondition_item = self.precondition[index]\n",
        "\n",
        "    tokenized_input = tokenizer.encode_plus( statement_item, precondition_item,\n",
        "                                            add_special_tokens = True,\n",
        "                                            max_length = self.max_length,\n",
        "                                            padding = 'max_length',\n",
        "                                            truncation = True,\n",
        "                                            return_attention_mask = True,\n",
        "                                            return_tensors = 'pt')\n",
        "    return {\n",
        "            'input_ids': tokenized_input['input_ids'].flatten(),\n",
        "            'attention_mask': tokenized_input['attention_mask'].flatten(),\n",
        "        }\n",
        "                                          \n",
        "        "
      ],
      "metadata": {
        "id": "YEcglTtQ4PU1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = CreateTestDataset(test_df['statement'], test_df['precondition'], \n",
        "                              tokenizer, max_length)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data,\n",
        "                                        batch_size=batch_size,\n",
        "                                        shuffle=False,\n",
        "                                       num_workers=2)"
      ],
      "metadata": {
        "id": "b36begqh4PQ_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking test dataset\n",
        "test_data.__getitem__(0)\n"
      ],
      "metadata": {
        "id": "BoDRvB9s4PPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Testing Code\n",
        "\n",
        "pred_label = []\n",
        "for j, sample in enumerate(test_dataloader):\n",
        "\n",
        "  sample_input_ids = sample['input_ids'].to(device)\n",
        "  sample_atten_mask =sample['attention_mask'].to(device)\n",
        "\n",
        "\n",
        "  outputs = model(sample_input_ids, \n",
        "          attention_mask=sample_atten_mask)\n",
        "  test_preds_batch = outputs[0]\n",
        "  test_preds_batch = test_preds_batch.detach().cpu().numpy()\n",
        "\n",
        "  if j != 0: \n",
        "      pred_label = np.vstack((pred_label, test_preds_batch))\n",
        "\n",
        "  else:\n",
        "      pred_label = test_preds_batch\n",
        "  \n",
        "\n",
        "final_preds = np.argmax(pred_label, axis=1)"
      ],
      "metadata": {
        "id": "LpNIjFnp4bM5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_preds)"
      ],
      "metadata": {
        "id": "oSfVsZQc5t5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "90V71xi_6mmb"
      },
      "outputs": [],
      "source": [
        "# Eventually, results need to be a list of 2028 0 or 1's\n",
        "results = final_preds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(results)"
      ],
      "metadata": {
        "id": "WYeJXAg84bH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewQ8eC7D6mmd"
      },
      "source": [
        "### Output Prediction Result File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TIIiUZm6mme"
      },
      "source": [
        "You will need to submit a prediction result file. It should have 2028 lines, every line should be either 0 or 1, which is your model's prediction on the respective test set instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "IyRKk_U_6mme"
      },
      "outputs": [],
      "source": [
        "# suppose you had your model's predictions on the 2028 test cases read from test_enc_unlabeled.tsv, and \n",
        "#those results are in the list called 'results'\n",
        "assert (len(results) == 4850)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "2WB6_5It6mmf"
      },
      "outputs": [],
      "source": [
        "# make sure the results are not float numbers, but intergers 0 and 1\n",
        "results = [int(x) for x in results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "tKnpfkcs6mmf"
      },
      "outputs": [],
      "source": [
        "# write your prediction results to 'upload_predictions.txt' and upload that later\n",
        "with open('upload_predictions.txt', 'w', encoding = 'utf-8') as fp:\n",
        "    for x in results:\n",
        "        fp.write(str(x) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q05OQdHZTr9R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}